#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
================================================================================
V4 æ¨¡åž‹è¨“ç·´è…³æœ¬ - æ¨™æº–å®Œæ•´ç‰ˆæœ¬ (Standard)
================================================================================
æœ¬è…³æœ¬åŸ·è¡Œå®Œæ•´çš„ V4 è¨“ç·´æµç¨‹ï¼š
1. æ¸…é™¤èˆŠçš„ç‰¹å¾µå¿«å–ï¼ˆå¼·åˆ¶ç”¨æ–°çš„ 30 æ¬¡ MC Dropout æŽ¡æ¨£é‡ç®—ï¼‰
2. åŸ·è¡Œé è¨“ç·´ (Pre-training)
3. åŸ·è¡Œå¾®èª¿ (Fine-tuning) - æ¨™æº–å®Œæ•´æ­¥æ•¸

èˆ‡ V3 çš„å·®ç•°ï¼š
- Buy Agent Fine-tune: 1,000,000 æ­¥ (æ¨™æº–)
- Sell Agent Fine-tune: 300,000 æ­¥ (æ¨™æº–)

ä½œè€…ï¼šPhil Liang (Generated by Gemini)
æ—¥æœŸï¼š2025-12-07
================================================================================
"""

import os
import sys
import glob
import shutil
import pickle

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import yfinance as yf
import pandas as pd

# =============================================================================
# è¨­å®š
# =============================================================================
PROJECT_PATH = os.path.dirname(os.path.abspath(__file__))
CACHE_DIR = os.path.join(PROJECT_PATH, "data", "processed")
DATA_PATH = os.path.join(PROJECT_PATH, "data", "raw")
V4_MODELS_PATH = os.path.join(PROJECT_PATH, "models_hybrid_v4")
V4_RESULTS_PATH = os.path.join(PROJECT_PATH, "results_hybrid_v4")
SPLIT_DATE = '2023-01-01'

# V4: æ¨™æº–å®Œæ•´å¾®èª¿æ­¥æ•¸
PRETRAIN_BUY_STEPS = 1_000_000
PRETRAIN_SELL_STEPS = 500_000
FINETUNE_BUY_STEPS = 1_000_000
FINETUNE_SELL_STEPS = 300_000


def clear_cache():
    print("\n" + "=" * 60)
    print("Step A: Clear Cache")
    print("=" * 60)
    if not os.path.exists(CACHE_DIR):
        print(f"[Info] Cache dir not found: {CACHE_DIR}")
        return
    pkl_files = glob.glob(os.path.join(CACHE_DIR, "*.pkl"))
    if not pkl_files:
        print("[Info] No .pkl cache files found")
        return
    print(f"[Info] Found {len(pkl_files)} cache files")
    for f in pkl_files:
        try:
            os.remove(f)
            print(f"  Deleted: {os.path.basename(f)}")
        except Exception as e:
            print(f"  Failed: {os.path.basename(f)} - {e}")
    print("[Done] Cache cleared")


def run_pretraining():
    print("\n" + "=" * 60)
    print("Step B: Pre-training")
    print("=" * 60)
    print(f"  Buy Agent:  {PRETRAIN_BUY_STEPS:,} steps")
    print(f"  Sell Agent: {PRETRAIN_SELL_STEPS:,} steps")
    print(f"  Output:     {V4_MODELS_PATH}")
    print("=" * 60)
    
    os.makedirs(V4_MODELS_PATH, exist_ok=True)
    os.makedirs(DATA_PATH, exist_ok=True)
    
    import ptrl_hybrid_system as hybrid
    import torch
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[System] Device: {device}")
    
    print("\n[System] Loading LSTM models...")
    hybrid.load_best_lstm_models()
    
    print("\n[Data] Downloading global index data...")
    raw_data = hybrid.fetch_index_data(DATA_PATH, start_date="2000-01-01", end_date=SPLIT_DATE)
    
    print("\n[Data] Computing features (30x MC Dropout)...")
    train_data = {}
    benchmark_df = raw_data.get("^TWII")
    for ticker, df in raw_data.items():
        try:
            processed = hybrid.calculate_features(df, benchmark_df, ticker, use_cache=False)
            if len(processed) > 100:
                train_data[ticker] = processed
                print(f"  OK {ticker}: {len(processed)} rows")
        except Exception as e:
            print(f"  WARN {ticker}: {e}")
    
    print(f"\n[Training] Starting pre-training...")
    hybrid.run_pretraining(train_data, V4_MODELS_PATH, device)
    print(f"\n[Done] Pre-training complete! Saved to {V4_MODELS_PATH}/")


def run_finetuning():
    print("\n" + "=" * 60)
    print("Step C: Fine-tuning (Standard)")
    print("=" * 60)
    print(f"  Buy Agent:  {FINETUNE_BUY_STEPS:,} steps (æ¨™æº–)")
    print(f"  Sell Agent: {FINETUNE_SELL_STEPS:,} steps (æ¨™æº–)")
    print(f"  Output:     {V4_MODELS_PATH}")
    print("=" * 60)
    
    import ptrl_hybrid_system as hybrid
    import torch
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"[System] Device: {device}")
    
    hybrid.load_best_lstm_models()
    
    print("\n[Data] Preparing ^TWII data...")
    cache_path = os.path.join(CACHE_DIR, "_TWII_features.pkl")
    
    if os.path.exists(cache_path):
        print(f"[Cache] Loading ^TWII features...")
        with open(cache_path, 'rb') as f:
            twii_full_df = pickle.load(f)
    else:
        print("[Compute] Loading ^TWII from local CSV...")
        # [Modify] ä½¿ç”¨æœ¬åœ°è³‡æ–™è¼‰å…¥å‡½æ•¸
        twii_raw = hybrid._load_local_twii_data(start_date="2000-01-01")
        
        twii_full_df = hybrid.calculate_features(twii_raw, twii_raw, ticker="^TWII", use_cache=True)
    
    print(f"[Data] ^TWII data: {len(twii_full_df)} rows")
    
    split_date = pd.Timestamp(SPLIT_DATE)
    twii_finetune_df = twii_full_df[twii_full_df.index < split_date]
    twii_eval_df = twii_full_df[twii_full_df.index >= split_date]
    
    print(f"  Fine-tuning set: {len(twii_finetune_df)} rows (< {SPLIT_DATE})")
    print(f"  Eval set:        {len(twii_eval_df)} rows (>= {SPLIT_DATE})")
    
    finetune_data = {'^TWII': twii_finetune_df}
    eval_data = {'^TWII': twii_eval_df}
    
    print(f"\n[Training] Starting fine-tuning (standard)...")
    hybrid.run_finetuning(finetune_data, eval_data, V4_MODELS_PATH, device,
                          finetune_buy_steps=FINETUNE_BUY_STEPS,
                          finetune_sell_steps=FINETUNE_SELL_STEPS)
    print(f"\n[Done] Fine-tuning complete! Saved to {V4_MODELS_PATH}/")


def print_next_steps():
    print("\n" + "=" * 60)
    print("âœ… V4 æ¨¡åž‹è¨“ç·´æµç¨‹å·²å®Œæˆï¼")
    print("=" * 60)
    print(f"""
ðŸ“ æ¨¡åž‹å„²å­˜ä½ç½®:
   {V4_MODELS_PATH}/ppo_buy_twii_final.zip
   {V4_MODELS_PATH}/ppo_sell_twii_final.zip

ðŸ“Š V4 ç‰¹é»ž (æ¨™æº–å®Œæ•´ç‰ˆ):
   - Buy Fine-tune: 1,000,000 steps
   - Sell Fine-tune: 300,000 steps

ðŸ’¡ daily_ops_dual.py å·²é è¨­ä½¿ç”¨ V3 å’Œ V4 æ¨¡åž‹é€²è¡Œé›™ç­–ç•¥æŽ¨è«–
""")


def check_pretrain_complete():
    buy_base = os.path.join(V4_MODELS_PATH, "ppo_buy_base.zip")
    sell_base = os.path.join(V4_MODELS_PATH, "ppo_sell_base.zip")
    return os.path.exists(buy_base) and os.path.exists(sell_base)


def check_finetune_complete():
    buy_final = os.path.join(V4_MODELS_PATH, "ppo_buy_twii_final.zip")
    sell_final = os.path.join(V4_MODELS_PATH, "ppo_sell_twii_final.zip")
    return os.path.exists(buy_final) and os.path.exists(sell_final)


def check_backtest_complete():
    result_chart = os.path.join(V4_RESULTS_PATH, "final_performance.png")
    return os.path.exists(result_chart)


def run_backtesting_step():
    print("\n" + "=" * 60)
    print("Step D: Backtesting")
    print("=" * 60)
    print(f"  Output: {V4_RESULTS_PATH}")
    print("=" * 60)
    
    os.makedirs(V4_RESULTS_PATH, exist_ok=True)
    
    import ptrl_hybrid_system as hybrid
    from stable_baselines3 import PPO
    
    hybrid.load_best_lstm_models()
    
    print("\n[Data] Preparing ^TWII data...")
    cache_path = os.path.join(CACHE_DIR, "_TWII_features.pkl")
    
    if os.path.exists(cache_path):
        print(f"[Cache] Loading ^TWII features...")
        with open(cache_path, 'rb') as f:
            twii_full_df = pickle.load(f)
    else:
        print("[Compute] Loading ^TWII from local CSV...")
        # [Modify] ä½¿ç”¨æœ¬åœ°è³‡æ–™è¼‰å…¥å‡½æ•¸
        twii_raw = hybrid._load_local_twii_data(start_date="2000-01-01")
        
        twii_full_df = hybrid.calculate_features(twii_raw, twii_raw, ticker="^TWII", use_cache=True)
    
    split_date = pd.Timestamp(SPLIT_DATE)
    twii_backtest_df = twii_full_df[twii_full_df.index >= split_date]
    
    print(f"[Data] Backtest period: {twii_backtest_df.index[0].strftime('%Y-%m-%d')} ~ {twii_backtest_df.index[-1].strftime('%Y-%m-%d')}")
    print(f"[Data] Backtest data: {len(twii_backtest_df)} rows")
    
    print("\n[Model] Loading V4 Fine-tuned models...")
    buy_model = PPO.load(os.path.join(V4_MODELS_PATH, "ppo_buy_twii_final.zip"))
    sell_model = PPO.load(os.path.join(V4_MODELS_PATH, "ppo_sell_twii_final.zip"))
    
    print("\n[Backtest] Running...")
    metrics = hybrid.run_backtesting(twii_backtest_df, buy_model, sell_model, V4_RESULTS_PATH, twii_full_df)
    
    print(f"\n[Done] Backtest complete! Results saved to {V4_RESULTS_PATH}/")
    return metrics


def main():
    print("=" * 60)
    print("V4 Model Training Script (Standard Fine-tuning)")
    print(f"   Buy Fine-tune: {FINETUNE_BUY_STEPS:,} steps | Sell Fine-tune: {FINETUNE_SELL_STEPS:,} steps")
    print("=" * 60)
    
    if not check_pretrain_complete():
        clear_cache()
    else:
        print("\n[Skip] Step A: Cache clearing (pre-training done)")
    
    if check_pretrain_complete():
        print("\n" + "=" * 60)
        print("[Skip] Step B: Pre-training complete")
        print(f"   Buy Base:  {V4_MODELS_PATH}/ppo_buy_base.zip")
        print(f"   Sell Base: {V4_MODELS_PATH}/ppo_sell_base.zip")
        print("=" * 60)
    else:
        run_pretraining()
    
    if check_finetune_complete():
        print("\n" + "=" * 60)
        print("[Skip] Step C: Fine-tuning complete")
        print(f"   Buy Final:  {V4_MODELS_PATH}/ppo_buy_twii_final.zip")
        print(f"   Sell Final: {V4_MODELS_PATH}/ppo_sell_twii_final.zip")
        print("=" * 60)
    else:
        run_finetuning()
    
    if check_backtest_complete():
        print("\n" + "=" * 60)
        print("[Skip] Step D: Backtest complete")
        print(f"   Result: {V4_RESULTS_PATH}/final_performance.png")
        print("=" * 60)
    else:
        run_backtesting_step()
    
    print_next_steps()


if __name__ == "__main__":
    main()
