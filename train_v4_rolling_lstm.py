#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
================================================================================
V4 Rolling LSTM Training Script
================================================================================
Rolling LSTM Update Strategyï¼š
- RL è¨“ç·´æœŸé–“ï¼Œæ¯å¹´æ›´æ–°ä¸€æ¬¡ LSTM æ¨¡å‹
- LSTM æ°¸é åªç”¨ RL ç•¶å‰è¨“ç·´å¹´ä»½ä¹‹å‰çš„è³‡æ–™è¨“ç·´
- ç¢ºä¿ RL çœ‹åˆ°çš„ LSTM é æ¸¬éƒ½æ˜¯ out-of-sample

LSTM çª—å£è¨­å®š (èˆ‡ daily_ops_dual.py å¯¦æˆ°ä¸€è‡´)ï¼š
- T+5: 2200 å¤© (~6 å¹´)
- T+1: 2000 å¤© (~5.5 å¹´)

ä½œè€…ï¼šPhil Liang (Generated by Gemini)
æ—¥æœŸï¼š2025-12-12
================================================================================
"""

import os
import sys
import argparse
import subprocess
import pickle
import glob
import shutil
from datetime import datetime, timedelta
from pathlib import Path

# Windows çµ‚ç«¯æ©Ÿ UTF-8 ç·¨ç¢¼è¨­å®š
if sys.platform == 'win32':
    sys.stdout.reconfigure(encoding='utf-8')

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

# =============================================================================
# è¨­å®š
# =============================================================================
PROJECT_PATH = Path(__file__).parent
CACHE_DIR = PROJECT_PATH / "data" / "processed"
DATA_PATH = PROJECT_PATH / "data" / "raw"

# LSTM æ¨¡å‹é è¨­è¼¸å‡ºè·¯å¾‘
DEFAULT_LSTM_5D_DIR = PROJECT_PATH / "saved_models_5d"
DEFAULT_LSTM_1D_DIR = PROJECT_PATH / "saved_models_multivariate"

# Rolling LSTM å°ˆç”¨æ¨¡å‹å„²å­˜è·¯å¾‘
ROLLING_LSTM_DIR = PROJECT_PATH / "rolling_lstm_models"

# RL æ¨¡å‹è¼¸å‡ºè·¯å¾‘
V4_ROLLING_MODELS_PATH = PROJECT_PATH / "models_hybrid_v4_rolling"
V4_ROLLING_RESULTS_PATH = PROJECT_PATH / "results_hybrid_v4_rolling"

# LSTM è¨“ç·´è…³æœ¬
SCRIPT_5D = "twii_model_registry_5d.py"
SCRIPT_1D = "twii_model_registry_multivariate.py"

# LSTM çª—å£è¨­å®š (æ—¥æ›†å¤©æ•¸ï¼Œèˆ‡å¯¦æˆ°ä¸€è‡´)
LSTM_WINDOW_5D = 2200  # ~6 å¹´
LSTM_WINDOW_1D = 2000  # ~5.5 å¹´

# RL è¨“ç·´è¨­å®š
RL_START_YEAR = 2006  # æœ€æ—©å¯é–‹å§‹çš„å¹´ä»½ (å›  T+5 éœ€è¦ 6 å¹´æ­·å²)
RL_END_YEAR = 2022    # è¨“ç·´çµæŸå¹´ä»½ (é©—è­‰æœŸå¾ 2023 é–‹å§‹)
SPLIT_DATE = '2023-01-01'

# å¾®èª¿æ­¥æ•¸ (èˆ‡ V4 ä¸€è‡´)
FINETUNE_BUY_STEPS_PER_YEAR = 60_000   # æ¯å¹´ç´„ 60K æ­¥
FINETUNE_SELL_STEPS_PER_YEAR = 20_000  # æ¯å¹´ç´„ 20K æ­¥


# =============================================================================
# è¼”åŠ©å‡½æ•¸
# =============================================================================
def calculate_lstm_dates(rl_year: int) -> dict:
    """
    è¨ˆç®—æŒ‡å®š RL è¨“ç·´å¹´ä»½å°æ‡‰çš„ LSTM è¨“ç·´æ—¥æœŸç¯„åœ
    
    Args:
        rl_year: RL è¨“ç·´çš„ç›®æ¨™å¹´ä»½ (e.g., 2010)
    
    Returns:
        dict åŒ…å« T+5 å’Œ T+1 çš„èµ·å§‹/çµæŸæ—¥æœŸ
    """
    # LSTM è¨“ç·´çµæŸæ—¥ = RL å¹´ä»½å‰ä¸€å¹´åº•
    end_date = datetime(rl_year - 1, 12, 31)
    
    # è¨ˆç®—èµ·å§‹æ—¥æœŸ
    start_5d = end_date - timedelta(days=LSTM_WINDOW_5D)
    start_1d = end_date - timedelta(days=LSTM_WINDOW_1D)
    
    return {
        'end_date': end_date.strftime('%Y-%m-%d'),
        'start_5d': start_5d.strftime('%Y-%m-%d'),
        'start_1d': start_1d.strftime('%Y-%m-%d'),
    }


def train_lstm_for_year(rl_year: int, dry_run: bool = False) -> bool:
    """
    è¨“ç·´æŒ‡å®šå¹´ä»½å°æ‡‰çš„ LSTM æ¨¡å‹
    
    Args:
        rl_year: RL è¨“ç·´çš„ç›®æ¨™å¹´ä»½
        dry_run: è‹¥ç‚º Trueï¼Œåªé¡¯ç¤ºè¨ˆç•«ä¸å¯¦éš›åŸ·è¡Œ
    
    Returns:
        æ˜¯å¦æˆåŠŸ
    """
    dates = calculate_lstm_dates(rl_year)
    
    print(f"\n{'='*60}")
    print(f"ğŸ“… LSTM Training for RL Year {rl_year}")
    print(f"{'='*60}")
    print(f"  LSTM è¨“ç·´çµæŸæ—¥: {dates['end_date']}")
    print(f"  T+5 è¨“ç·´èµ·å§‹æ—¥: {dates['start_5d']} ({LSTM_WINDOW_5D} å¤©)")
    print(f"  T+1 è¨“ç·´èµ·å§‹æ—¥: {dates['start_1d']} ({LSTM_WINDOW_1D} å¤©)")
    
    if dry_run:
        print("  [Dry Run] è·³éå¯¦éš›è¨“ç·´")
        return True
    
    # å‰µå»ºå¹´åº¦å°ˆå±¬ç›®éŒ„
    year_lstm_dir = ROLLING_LSTM_DIR / str(rl_year)
    year_lstm_5d_dir = year_lstm_dir / "saved_models_5d"
    year_lstm_1d_dir = year_lstm_dir / "saved_models_multivariate"
    year_lstm_dir.mkdir(parents=True, exist_ok=True)
    year_lstm_5d_dir.mkdir(exist_ok=True)
    year_lstm_1d_dir.mkdir(exist_ok=True)
    
    split_ratio = "0.99"  # èˆ‡å¯¦æˆ°ä¸€è‡´
    
    # 1. è¨“ç·´ T+5
    print(f"\n[Training] T+5 Model ({dates['start_5d']} ~ {dates['end_date']})...")
    cmd_5d = [
        sys.executable, str(PROJECT_PATH / SCRIPT_5D), "train",
        "--start", dates['start_5d'],
        "--end", dates['end_date'],
        "--split_ratio", split_ratio
    ]
    
    try:
        subprocess.run(cmd_5d, check=True, timeout=1800, cwd=PROJECT_PATH)
        print("[Training] âœ… T+5 è¨“ç·´å®Œæˆ")
        
        # è¤‡è£½åˆ°å¹´åº¦ç›®éŒ„
        if DEFAULT_LSTM_5D_DIR.exists():
            for f in DEFAULT_LSTM_5D_DIR.glob("*"):
                shutil.copy2(f, year_lstm_5d_dir)
            print(f"  âœ… å·²å°å­˜åˆ° {year_lstm_5d_dir}")
    except Exception as e:
        print(f"[Error] T+5 è¨“ç·´å¤±æ•—: {e}")
        return False
    
    # 2. è¨“ç·´ T+1
    print(f"\n[Training] T+1 Model ({dates['start_1d']} ~ {dates['end_date']})...")
    cmd_1d = [
        sys.executable, str(PROJECT_PATH / SCRIPT_1D), "train",
        "--start", dates['start_1d'],
        "--end", dates['end_date'],
        "--split_ratio", split_ratio
    ]
    
    try:
        subprocess.run(cmd_1d, check=True, timeout=1800, cwd=PROJECT_PATH)
        print("[Training] âœ… T+1 è¨“ç·´å®Œæˆ")
        
        # è¤‡è£½åˆ°å¹´åº¦ç›®éŒ„
        if DEFAULT_LSTM_1D_DIR.exists():
            for f in DEFAULT_LSTM_1D_DIR.glob("*"):
                shutil.copy2(f, year_lstm_1d_dir)
            print(f"  âœ… å·²å°å­˜åˆ° {year_lstm_1d_dir}")
    except Exception as e:
        print(f"[Error] T+1 è¨“ç·´å¤±æ•—: {e}")
        return False
    
    return True


def load_lstm_models_for_year(rl_year: int):
    """
    è¼‰å…¥æŒ‡å®šå¹´ä»½çš„ LSTM æ¨¡å‹ä¸¦æ³¨å…¥åˆ° core_system
    
    Args:
        rl_year: RL è¨“ç·´çš„ç›®æ¨™å¹´ä»½
    """
    import ptrl_hybrid_system as core_system
    from tensorflow import keras
    
    try:
        from twii_model_registry_5d import SelfAttention
    except ImportError:
        print("[Error] ç„¡æ³•å¼•ç”¨ SelfAttention é¡åˆ¥")
        return False
    
    year_lstm_dir = ROLLING_LSTM_DIR / str(rl_year)
    lstm_5d_dir = year_lstm_dir / "saved_models_5d"
    lstm_1d_dir = year_lstm_dir / "saved_models_multivariate"
    
    def load_model_components(model_dir):
        keras_files = list(Path(model_dir).glob("*.keras"))
        if not keras_files:
            return None, None, None, None
        
        latest_keras = sorted(keras_files)[-1]
        model = keras.models.load_model(str(latest_keras), custom_objects={'SelfAttention': SelfAttention})
        
        # è¼‰å…¥ Scalers
        scaler_feat_file = str(latest_keras).replace('model_', 'feature_scaler_').replace('.keras', '.pkl')
        scaler_tgt_file = str(latest_keras).replace('model_', 'target_scaler_').replace('.keras', '.pkl')
        meta_file = str(latest_keras).replace('model_', 'meta_').replace('.keras', '.json')
        
        scaler_feat, scaler_tgt, meta = None, None, {}
        
        if os.path.exists(scaler_feat_file):
            with open(scaler_feat_file, 'rb') as f:
                scaler_feat = pickle.load(f)
        
        if os.path.exists(scaler_tgt_file):
            with open(scaler_tgt_file, 'rb') as f:
                scaler_tgt = pickle.load(f)
        else:
            scaler_tgt = scaler_feat
        
        if os.path.exists(meta_file):
            import json
            with open(meta_file, 'r', encoding='utf-8') as f:
                meta = json.load(f)
        
        return model, scaler_feat, scaler_tgt, meta
    
    print(f"\n[Model Injection] è¼‰å…¥ {rl_year} å¹´çš„ LSTM æ¨¡å‹...")
    
    m5d, sf5d, st5d, meta5d = load_model_components(lstm_5d_dir)
    m1d, sf1d, st1d, meta1d = load_model_components(lstm_1d_dir)
    
    if m5d is None or m1d is None:
        print(f"[Error] æ‰¾ä¸åˆ° {rl_year} å¹´çš„ LSTM æ¨¡å‹")
        return False
    
    # æ³¨å…¥ä¸»ç³»çµ±
    if not hasattr(core_system, '_LSTM_MODELS'):
        core_system._LSTM_MODELS = {}
    
    core_system._LSTM_MODELS.update({
        'model_5d': m5d, 'scaler_feat_5d': sf5d, 'scaler_tgt_5d': st5d, 'meta_5d': meta5d,
        'model_1d': m1d, 'scaler_feat_1d': sf1d, 'scaler_tgt_1d': st1d, 'meta_1d': meta1d,
        'loaded': True
    })
    
    print(f"  âœ… {rl_year} å¹´ LSTM æ¨¡å‹æ³¨å…¥å®Œæˆ")
    return True


def run_rolling_finetuning(start_year: int, end_year: int, dry_run: bool = False):
    """
    åŸ·è¡Œ Rolling LSTM å¾®èª¿è¨“ç·´
    
    Args:
        start_year: èµ·å§‹å¹´ä»½
        end_year: çµæŸå¹´ä»½
        dry_run: è‹¥ç‚º Trueï¼Œåªé¡¯ç¤ºè¨ˆç•«ä¸å¯¦éš›åŸ·è¡Œ
    """
    import ptrl_hybrid_system as hybrid
    import pandas as pd
    import torch
    
    print("\n" + "=" * 70)
    print("ğŸš€ Rolling LSTM Fine-tuning Strategy")
    print("=" * 70)
    print(f"  è¨“ç·´å¹´ä»½ç¯„åœ: {start_year} ~ {end_year}")
    print(f"  LSTM çª—å£: T+5={LSTM_WINDOW_5D}å¤©, T+1={LSTM_WINDOW_1D}å¤©")
    print("=" * 70)
    
    if dry_run:
        print("\nğŸ“‹ [Dry Run Mode] è¨“ç·´è¨ˆç•«é è¦½ï¼š")
        for year in range(start_year, end_year + 1):
            dates = calculate_lstm_dates(year)
            print(f"\nå¹´åº¦ {year}:")
            print(f"  - LSTM T+5: {dates['start_5d']} ~ {dates['end_date']}")
            print(f"  - LSTM T+1: {dates['start_1d']} ~ {dates['end_date']}")
            print(f"  - RL è¨“ç·´: {year}-01-01 ~ {year}-12-31")
        print("\n[Dry Run] å®Œæˆé è¦½ï¼ŒæœªåŸ·è¡Œå¯¦éš›è¨“ç·´ã€‚")
        return
    
    # å‰µå»ºè¼¸å‡ºç›®éŒ„
    V4_ROLLING_MODELS_PATH.mkdir(parents=True, exist_ok=True)
    V4_ROLLING_RESULTS_PATH.mkdir(parents=True, exist_ok=True)
    
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"\n[System] Device: {device}")
    
    # è¼‰å…¥å®Œæ•´ TWII è³‡æ–™
    print("\n[Data] Loading ^TWII from local CSV...")
    twii_raw = hybrid._load_local_twii_data(start_date="2000-01-01")
    
    # æª¢æŸ¥æ˜¯å¦æœ‰é è¨“ç·´æ¨¡å‹
    buy_base_path = V4_ROLLING_MODELS_PATH / "ppo_buy_base.zip"
    if not buy_base_path.exists():
        print("\n[Warning] æœªæ‰¾åˆ°é è¨“ç·´æ¨¡å‹ï¼Œéœ€å…ˆåŸ·è¡Œé è¨“ç·´...")
        print("è«‹å…ˆåŸ·è¡Œ: python train_v4_models.py (é è¨“ç·´éƒ¨åˆ†)")
        print("æˆ–è¤‡è£½ç¾æœ‰çš„ ppo_buy_base.zip å’Œ ppo_sell_base.zip åˆ°:")
        print(f"  {V4_ROLLING_MODELS_PATH}")
        return
    
    # å¹´åº¦æ»¾å‹•è¨“ç·´
    for year in range(start_year, end_year + 1):
        print("\n" + "=" * 70)
        print(f"ğŸ“… Year {year} / {end_year}")
        print("=" * 70)
        
        # Step 1: è¨“ç·´ LSTM
        success = train_lstm_for_year(year, dry_run=False)
        if not success:
            print(f"[Error] LSTM è¨“ç·´å¤±æ•—æ–¼ {year} å¹´ï¼Œçµ‚æ­¢è¨“ç·´")
            return
        
        # Step 2: è¼‰å…¥ LSTM æ¨¡å‹
        success = load_lstm_models_for_year(year)
        if not success:
            print(f"[Error] LSTM æ¨¡å‹è¼‰å…¥å¤±æ•—æ–¼ {year} å¹´ï¼Œçµ‚æ­¢è¨“ç·´")
            return
        
        # Step 3: è¨ˆç®—è©²å¹´åº¦ç‰¹å¾µ
        print(f"\n[Feature] è¨ˆç®— {year} å¹´ç‰¹å¾µ...")
        year_start = pd.Timestamp(f"{year}-01-01")
        year_end = pd.Timestamp(f"{year}-12-31")
        
        # ç¯©é¸è©²å¹´åº¦è³‡æ–™
        year_df = twii_raw[(twii_raw.index >= year_start) & (twii_raw.index <= year_end)]
        
        if len(year_df) == 0:
            print(f"[Warning] {year} å¹´ç„¡è³‡æ–™ï¼Œè·³é")
            continue
        
        # éœ€è¦æ›´å¤šæ­·å²è³‡æ–™ä¾†è¨ˆç®—ç‰¹å¾µ
        feature_start = year_start - pd.Timedelta(days=365)
        extended_df = twii_raw[(twii_raw.index >= feature_start) & (twii_raw.index <= year_end)]
        
        # è¨ˆç®—ç‰¹å¾µ (ä½¿ç”¨ç•¶å¹´çš„ LSTM æ¨¡å‹)
        features_df = hybrid.calculate_features(extended_df, extended_df, ticker="^TWII", use_cache=False)
        
        # åªå–è©²å¹´åº¦çš„è³‡æ–™
        year_features = features_df[(features_df.index >= year_start) & (features_df.index <= year_end)]
        
        print(f"  è³‡æ–™ç­†æ•¸: {len(year_features)}")
        
        # Step 4: RL å¾®èª¿
        print(f"\n[Fine-tune] è¨“ç·´ {year} å¹´ RL æ¨¡å‹...")
        
        from stable_baselines3 import PPO
        from stable_baselines3.common.env_util import make_vec_env
        from stable_baselines3.common.vec_env import SubprocVecEnv
        import multiprocessing
        
        # ä½¿ç”¨å¤šç’°å¢ƒä¸¦è¡Œè¨“ç·´ (æé«˜ FPS)
        n_envs = min(8, max(1, multiprocessing.cpu_count() - 1))
        
        finetune_data = {'^TWII': year_features}
        
        # è¨ˆç®—è©²å¹´åº¦çš„è¨“ç·´æ­¥æ•¸ (æ ¹æ“šè³‡æ–™é‡èª¿æ•´)
        data_ratio = len(year_features) / 250  # 250 = ä¸€å¹´ç´„äº¤æ˜“æ—¥
        buy_steps = int(FINETUNE_BUY_STEPS_PER_YEAR * data_ratio)
        sell_steps = int(FINETUNE_SELL_STEPS_PER_YEAR * data_ratio)
        
        print(f"  Buy æ­¥æ•¸: {buy_steps:,} | Sell æ­¥æ•¸: {sell_steps:,}")
        
        # è¼‰å…¥ä¸Šä¸€å¹´çš„æ¨¡å‹æˆ–åŸºç¤æ¨¡å‹
        if year == start_year:
            buy_model_path = V4_ROLLING_MODELS_PATH / "ppo_buy_base.zip"
            sell_model_path = V4_ROLLING_MODELS_PATH / "ppo_sell_base.zip"
        else:
            buy_model_path = V4_ROLLING_MODELS_PATH / f"ppo_buy_{year-1}.zip"
            sell_model_path = V4_ROLLING_MODELS_PATH / f"ppo_sell_{year-1}.zip"
        
        # Buy Agent è¨“ç·´
        try:
            buy_env = make_vec_env(
                hybrid.BuyEnvHybrid, n_envs=n_envs, vec_env_cls=SubprocVecEnv,
                env_kwargs={'data_dict': finetune_data, 'is_training': True}
            )
            print(f"  [System] ä½¿ç”¨ {n_envs} å€‹ä¸¦è¡Œç’°å¢ƒ")
            
            buy_model = PPO.load(str(buy_model_path), env=buy_env, device=device)
            buy_model.learning_rate = 1e-5
            buy_model.learn(total_timesteps=buy_steps, reset_num_timesteps=False)
            
            buy_save_path = V4_ROLLING_MODELS_PATH / f"ppo_buy_{year}.zip"
            buy_model.save(str(buy_save_path))
            buy_env.close()
            
            print(f"  âœ… Buy Agent å·²å„²å­˜: {buy_save_path.name}")
        except Exception as e:
            print(f"  âŒ Buy Agent è¨“ç·´å¤±æ•—: {e}")
            return
        
        # Sell Agent è¨“ç·´
        try:
            sell_env = make_vec_env(
                hybrid.SellEnvHybrid, n_envs=n_envs, vec_env_cls=SubprocVecEnv,
                env_kwargs={'data_dict': finetune_data}
            )
            
            sell_model = PPO.load(str(sell_model_path), env=sell_env, device=device)
            sell_model.learning_rate = 1e-5
            sell_model.learn(total_timesteps=sell_steps, reset_num_timesteps=False)
            
            sell_save_path = V4_ROLLING_MODELS_PATH / f"ppo_sell_{year}.zip"
            sell_model.save(str(sell_save_path))
            sell_env.close()
            
            print(f"  âœ… Sell Agent å·²å„²å­˜: {sell_save_path.name}")
        except Exception as e:
            print(f"  âŒ Sell Agent è¨“ç·´å¤±æ•—: {e}")
            return
    
    # è¤‡è£½æœ€çµ‚æ¨¡å‹ç‚º final
    final_buy = V4_ROLLING_MODELS_PATH / f"ppo_buy_{end_year}.zip"
    final_sell = V4_ROLLING_MODELS_PATH / f"ppo_sell_{end_year}.zip"
    
    if final_buy.exists():
        shutil.copy2(final_buy, V4_ROLLING_MODELS_PATH / "ppo_buy_twii_final.zip")
    if final_sell.exists():
        shutil.copy2(final_sell, V4_ROLLING_MODELS_PATH / "ppo_sell_twii_final.zip")
    
    print("\n" + "=" * 70)
    print("âœ… Rolling LSTM Training Completed!")
    print("=" * 70)
    print(f"  æ¨¡å‹å„²å­˜ä½ç½®: {V4_ROLLING_MODELS_PATH}")
    print(f"  æœ€çµ‚æ¨¡å‹: ppo_buy_twii_final.zip, ppo_sell_twii_final.zip")
    print("=" * 70)


def main():
    parser = argparse.ArgumentParser(description="V4 Rolling LSTM Training Script")
    parser.add_argument("--dry-run", action="store_true", help="åªé¡¯ç¤ºè¨“ç·´è¨ˆç•«ï¼Œä¸å¯¦éš›åŸ·è¡Œ")
    parser.add_argument("--start-year", type=int, default=RL_START_YEAR, help=f"èµ·å§‹å¹´ä»½ (default: {RL_START_YEAR})")
    parser.add_argument("--end-year", type=int, default=RL_END_YEAR, help=f"çµæŸå¹´ä»½ (default: {RL_END_YEAR})")
    parser.add_argument("--lstm-only", action="store_true", help="åªè¨“ç·´ LSTM æ¨¡å‹ï¼Œä¸è¨“ç·´ RL")
    
    args = parser.parse_args()
    
    print("=" * 70)
    print("V4 Rolling LSTM Training Script")
    print("=" * 70)
    
    if args.lstm_only:
        # åªè¨“ç·´ LSTM
        for year in range(args.start_year, args.end_year + 1):
            train_lstm_for_year(year, dry_run=args.dry_run)
    else:
        # å®Œæ•´æ»¾å‹•è¨“ç·´
        run_rolling_finetuning(args.start_year, args.end_year, dry_run=args.dry_run)


if __name__ == "__main__":
    main()
